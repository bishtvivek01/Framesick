{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f767aa",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Conv2D, Concatenate, UpSampling2D, MaxPooling2D, Activation, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow_addons.image import dense_image_warp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642ca4e2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === 1. Parameters ===\n",
    "target_size = (540,960)\n",
    "# Construct the full path to the dataset directory\n",
    "dataset_dir = os.path.join(os.getcwd(), \"dataset\", \"videos\", \"thirtyfps\")\n",
    "output_dir = \"dataset/videos/sixtyfps\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "batch_size = 1 # Reduce if out-of-memory\n",
    "epochs = 10\n",
    "\n",
    "print(f\"Constructed dataset_dir: {dataset_dir}\")\n",
    "\n",
    "try:\n",
    "        files_in_dir = os.listdir(dataset_dir)\n",
    "        print(f\"Contents of dataset directory: {files_in_dir}\")\n",
    "        if not files_in_dir:\n",
    "            print(\"Warning: Dataset directory is empty.\")\n",
    "except Exception as e:\n",
    "        print(f\"Could not list contents of directory: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b40f25",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === 2. Data Loader and Generator ===\n",
    "def load_triplets_from_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if target_size:\n",
    "            frame = cv2.resize(frame, target_size)\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    triplets = []\n",
    "    for i in range(len(frames) - 2):\n",
    "        triplets.append((frames[i], frames[i+1], frames[i+2]))\n",
    "    return triplets\n",
    "\n",
    "def get_all_triplets():\n",
    "    triplets = []\n",
    "    for file in os.listdir(dataset_dir):\n",
    "        if file.endswith(\".mp4\"):\n",
    "            triplets.extend(load_triplets_from_video(os.path.join(dataset_dir, file)))\n",
    "    return triplets\n",
    "\n",
    "class FlowTripletGenerator(tf.keras.utils.Sequence):\n",
    "    def __init__(self, triplets, batch_size):\n",
    "        self.triplets = triplets\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch = self.triplets[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        inputs, targets = [], []\n",
    "        for f0, f1, f2 in batch:\n",
    "            f0, f1, f2 = f0 / 255.0, f1 / 255.0, f2 / 255.0\n",
    "            inputs.append(np.concatenate([f0, f2], axis=-1))\n",
    "            targets.append(f1)\n",
    "        return np.array(inputs), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24281289",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def build_deeper_model():\n",
    "\n",
    " inp = Input(shape=(None, None, 6))\n",
    "\n",
    " # Encoder\n",
    "\n",
    " x = Conv2D(32, 3, padding='same')(inp)\n",
    "\n",
    " x = BatchNormalization()(x)\n",
    "\n",
    " x = ReLU()(x)\n",
    "\n",
    " x = Conv2D(32, 3, padding='same')(x)\n",
    "\n",
    " x = ReLU()(x)\n",
    "\n",
    " x = MaxPooling2D()(x)\n",
    "\n",
    " x = Conv2D(64, 3, padding='same')(x)\n",
    "\n",
    " x = BatchNormalization()(x)\n",
    "\n",
    " x = ReLU()(x)\n",
    "\n",
    " x = Conv2D(64, 3, padding='same')(x)\n",
    "\n",
    " x = ReLU()(x)\n",
    "\n",
    " x = MaxPooling2D()(x)\n",
    "\n",
    " # Bottleneck\n",
    "\n",
    " x = Conv2D(128, 3, padding='same')(x)\n",
    "\n",
    " x = BatchNormalization()(x)\n",
    "\n",
    "x = ReLU()(x)\n",
    "\n",
    " x = Conv2D(128, 3, padding='same')(x)\n",
    "\n",
    " x = ReLU()(x)\n",
    "\n",
    " # Decoder\n",
    "\n",
    " x = UpSampling2D()(x)\n",
    "\n",
    " x = Conv2D(64, 3, padding='same')(x)\n",
    "\n",
    " x = BatchNormalization()(x)\n",
    "\n",
    " x = ReLU()(x)\n",
    "\n",
    " x = Conv2D(64, 3, padding='same')(x)\n",
    "\n",
    " x = ReLU()(x)\n",
    "\n",
    " x = UpSampling2D()(x)\n",
    "\n",
    " x = Conv2D(32, 3, padding='same')(x)\n",
    "\n",
    " x = BatchNormalization()(x)\n",
    "\n",
    " x = ReLU()(x)\n",
    "\n",
    " x = Conv2D(32, 3, padding='same')(x)\n",
    "\n",
    " x = ReLU()(x)\n",
    "\n",
    " # Output Flow Map\n",
    "\n",
    " flow = Conv2D(2, 3, padding='same', activation=None)(x)\n",
    "\n",
    " model = Model(inputs=inp, outputs=flow)\n",
    "\n",
    " return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568c4396",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === 4. Frame Warping Utility ===\n",
    "def warp_frame(frame, flow):\n",
    "    h, w = frame.shape[:2]\n",
    "    grid_x, grid_y = tf.meshgrid(tf.range(w), tf.range(h))\n",
    "    grid = tf.stack([grid_y, grid_x], axis=-1)\n",
    "    grid = tf.cast(grid, tf.float32)\n",
    "    flow = tf.image.resize(flow, (h, w))\n",
    "    coords = grid + flow[0]\n",
    "    warped = dense_image_warp(tf.expand_dims(frame, 0), tf.expand_dims(flow[0], 0))\n",
    "    return tf.squeeze(warped, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8caf63b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === 5. Training ===\n",
    "triplets = get_all_triplets()\n",
    "gen = FlowTripletGenerator(triplets, batch_size)\n",
    "model = build_model()\n",
    "optimizer = Adam(1e-4)\n",
    "\n",
    "@tf.function\n",
    "def train_step(x, y):\n",
    "    with tf.GradientTape() as tape:\n",
    "        flow = model(x, training=True)\n",
    "        f0, f2 = x[..., :3], x[..., 3:]\n",
    "        warped_f0 = dense_image_warp(f0, flow / 2.0)\n",
    "        warped_f2 = dense_image_warp(f2, -flow / 2.0)\n",
    "        pred = (warped_f0 + warped_f2) / 2.0\n",
    "        loss = tf.reduce_mean(tf.square(y - pred))\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    for i in range(len(gen)):\n",
    "        x_batch, y_batch = gen[i]\n",
    "        loss = train_step(tf.convert_to_tensor(x_batch, dtype=tf.float32),\n",
    "                          tf.convert_to_tensor(y_batch, dtype=tf.float32))\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Batch {i}, Loss: {loss.numpy():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191a6953",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model.save(\"flow_interpolation_model.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5ac17e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model before using it\n",
    "model = load_model(\"flow_interpolation_model.keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67184724",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === 6. Inference and Visualization ===\n",
    "def interpolate_frame(f0, f2):\n",
    "    import numpy as np\n",
    "    from tensorflow_addons.image import dense_image_warp\n",
    "\n",
    "    f0 = f0.astype(np.float32)\n",
    "    f2 = f2.astype(np.float32)\n",
    "\n",
    "    # Concatenate frames and predict optical flow\n",
    "    inp = np.concatenate([f0, f2], axis=-1) / 255.0\n",
    "    flow = model.predict(np.expand_dims(inp, 0))[0]\n",
    "\n",
    "    # Add batch dimension\n",
    "    f0_batch = np.expand_dims(f0 / 255.0, axis=0)\n",
    "    f2_batch = np.expand_dims(f2 / 255.0, axis=0)\n",
    "    flow_batch = np.expand_dims(flow, axis=0)\n",
    "\n",
    "    # Warp both frames\n",
    "    warped_f0 = dense_image_warp(f0_batch, flow_batch / 2.0)[0]\n",
    "    warped_f2 = dense_image_warp(f2_batch, -flow_batch / 2.0)[0]\n",
    "\n",
    "    # Average warped results\n",
    "    interp = (warped_f0 + warped_f2) / 2.0\n",
    "    interp = np.clip(interp * 255.0, 0, 255).astype(np.uint8)\n",
    "    return interp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8aa73",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# === 7. Video Conversion Utilities ===\n",
    "def extract_frames_from_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def interpolate_video_frames(frames):\n",
    "    output_frames = []\n",
    "    for i in range(len(frames) - 1):\n",
    "        f0 = frames[i]\n",
    "        f2 = frames[i + 1]\n",
    "        mid = interpolate_frame(f0, f2)\n",
    "        output_frames.extend([f0, mid])\n",
    "    output_frames.append(frames[-1])\n",
    "    return output_frames\n",
    "\n",
    "def save_video_from_frames(frames, path, fps):\n",
    "    h, w = frames[0].shape[:2]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(path, fourcc, fps, (w, h))\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708368bf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Specify your video file path\n",
    "input_video_path = \"dataset\\\\videos\\\\thirtyfps\\\\video-25- Made with Clipchamp.mp4\"\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(input_video_path):\n",
    "    print(f\"File exists: {input_video_path}\")\n",
    "else:\n",
    "    print(f\"File does not exist at the specified path: {input_video_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11bbbe",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "# === 8. Perform Full Video Conversion with Visualization of All Interpolated Frames ===\n",
    "input_video_path = \"dataset\\\\videos\\\\thirtyfps\\\\video-25- Made with Clipchamp.mp4\"\n",
    "video_name = os.path.splitext(os.path.basename(input_video_path))[0]\n",
    "output_video_path = os.path.join(output_dir, f\"{video_name}_60fps.mp4\")\n",
    "\n",
    "# Step 1: Extract frames\n",
    "input_frames = extract_frames_from_video(input_video_path)\n",
    "\n",
    "# Step 2: Interpolate frames\n",
    "interpolated_frames = interpolate_video_frames(input_frames)\n",
    "\n",
    "# Step 3: Save video\n",
    "save_video_from_frames(interpolated_frames, output_video_path, fps=60)\n",
    "\n",
    "# Step 4: Visualize all interpolated frames between pairs\n",
    "for i in range(len(input_frames) - 1):\n",
    "    f0 = input_frames[i]\n",
    "    f2 = input_frames[i + 1]\n",
    "    mid = interpolate_frame(f0, f2)\n",
    "\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(cv2.cvtColor(f0, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Original Frame {i}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(cv2.cvtColor(mid, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Interpolated Frame\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(cv2.cvtColor(f2, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(f\"Original Frame {i + 1}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(f\"\\nSaved interpolated video to: {output_video_path}\")\n",
    "print(\"Model ready for high-resolution interpolation and video conversion.\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
